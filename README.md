# Self-Attentive
Implementation of ["A Structured Self-Attentive Sentence Embedding"](https://arxiv.org/abs/1703.03130)

## Result
Accuracy: 0.85


## Visualization
#### Multi annotation vector - multi *r* hops<br>
<img src="image/multi_attention.png" alt="multi attention" width="720px"/><br>

#### Single annotation vector - single *r* hop<br>
<img src="image/single_attention.png" alt="single attention" width="720px"/><br>


## Reference
<https://arxiv.org/abs/1703.03130><br>
<https://github.com/flrngel/Self-Attentive-tensorflow>

